{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93UUxIQiEfIQ"
   },
   "source": [
    "# Lab 4 - DeepONets\n",
    "DeepONets are neural network architectures designed to learn operators (i.e., mappings between functions). Consider the one dimensional boundary value problem\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\nabla\\cdot\\left(a\\nabla u^a\\right) &= f \\quad \\text{in } (0,1)=:\\Omega\\\\\n",
    "u(0) = u(1) &= 0.\n",
    "\\end{aligned}\n",
    "$$\n",
    "For some value $a_{\\min{}}$, we define the admissible data set \n",
    "$$\n",
    "\\mathcal{A} = \\left\\{a\\in L^\\infty(\\Omega) : a(x)\\geq a_{\\min{}}\\text{ almost everywhere}\\right\\}\n",
    "$$\n",
    "and the solution operator \n",
    "$$\n",
    "\\mathcal{S}:\n",
    "\\begin{cases} \\mathcal{A} \\to H^1_0(\\Omega)\\\\\n",
    "a\\mapsto u^a.\n",
    "\\end{cases}\n",
    "$$\n",
    "We want to approximate the operator $\\mathcal{S}$ over some set $\\mathcal{D}\\subset\\mathcal{A}$ with a deepONet $\\mathcal{G}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9RB9ptaREbnI"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from DNN import DeepNet \n",
    "from utilities import plot_data, plot_results, LprelLoss\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSGMxilNEsOz"
   },
   "source": [
    "# Data Loading\n",
    "We fix $f=1$ and consider the data set\n",
    "$$\n",
    "\\mathcal{D} = \\left\\{ a(x) = 1+\\sum_{i=1}^3 y_i \\mathbb{1}_{((i-1)/3, i/3)}(x): y_i\\in (0,8)\\right\\}\n",
    "$$\n",
    "And solve the problem with linear finite elements. The code to solve the problem is given in the files `FEsolver.py` and `data_gen.ipynb`, though these require installing `FEniCSx`. To use the data, you can also load it from the respective files, that contain\n",
    "- coordinates $x_1, \\dots, x_M$\n",
    "- coefficient values $a(x_1), \\dots, a(x_M)$\n",
    "- solution values $u(x_1), \\dots, u(x_M)$\n",
    "- solution gradient $u'(x_1), \\dots, u'(x_M)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.load(\"data/x_train.pt\")\n",
    "coefs = torch.load(\"data/a_train.pt\")\n",
    "solutions = torch.load(\"data/u_train.pt\")\n",
    "grad_solutions = torch.load(\"data/gradu_train.pt\")\n",
    "\n",
    "# check the dimension of the data\n",
    "print(\"Dimension of x: \", x.shape)\n",
    "print(\"Dimension of coefs: \", coefs.shape)\n",
    "print(\"Dimension of solutions: \", solutions.shape)\n",
    "print(\"Dimension of gradients of solutions: \", grad_solutions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot some input-output pairs\n",
    "Use the function `plot_data` provided in `utilities.py` to plot some $(a, \\mathcal{S}(a))$ pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(x, {'Coefficient': coefs, 'Solution': solutions}, num_samples_to_plot=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(x, {'Solution': solutions, 'Gradient': grad_solutions}, num_samples_to_plot=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepONet architecture\n",
    "We now define the `DeepONet` class. We will use the `DeepNet` class that we have used in the previous labs.\n",
    "A deep operator network is composed of\n",
    "- a neural network $\\Phi_{\\mathrm{app}} : \\mathbb{R}^M\\to \\mathbb{R}^N$ (branch network)\n",
    "- a neural network $\\Phi_{\\mathrm{dec}} : \\mathbb{R}^d \\to \\mathbb{R}^N$ (trunk network)\n",
    "\n",
    "The `forward` function will take as input a point $x\\in\\mathbb{R^d}$ and a vector $a_1, \\dots a_M \\in \\mathbb{R}^M$ and return\n",
    "$$\n",
    "\\mathcal{G}(\\mathcal{E}(a))(x) = \\Phi_{\\mathrm{app}}(a_1, \\dots, a_M) \\cdot \\Phi_{\\mathrm{dec}}(x)\n",
    "$$\n",
    "An implementation detail: we want to be able to evaluate on multiple points at once: the function above should be implemented so that if instead of a single point $x$ we have $\\mathbf{x} = [x_1, \\dots, x_p]^\\top$, the function above should return\n",
    "$$\n",
    "\\Big(\\Phi_{\\mathrm{app}}(a_1, \\dots, a_M) \\cdot \\Phi_{\\mathrm{dec}}(x_i)\\Big)_{i=1}^p.\n",
    "$$\n",
    "The function takes as input the activation functions, the dimensions $M$, $d$, the widths of the layers, the dimension $N$, and a flag `bc`. If the flag is set to `True` the forward function above is replaced by\n",
    "$$\n",
    "\\Phi_{\\mathrm{app}}(a_1, \\dots, a_M) \\cdot \\big(x(1-x)\\Phi_{\\mathrm{dec}}(x)\\big)\n",
    "$$\n",
    "so that the boundary conditions are automatically satisfied.\n",
    "\n",
    "We will also define a class method `grad_forward` that computes the derivative\n",
    "$$\n",
    "\\Big(\\nabla_x \\mathcal{G}(\\mathcal{E}(a))\\Big)(x) = \\Phi_{\\mathrm{app}}(a_1, \\dots, a_M) \\cdot \\Big(\\nabla_x\\Phi_{\\mathrm{dec}}\\Big)(x)\n",
    "$$\n",
    "Note that this function is not used for the training, but only to inspect the results. You can postpone its implementation (and comment the corresponding part of the code in the next sections)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Im3Yrr1l2v5I"
   },
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cpu\")\n",
    "torch.set_default_device(device)\n",
    "\n",
    "class DeepONet(nn.Module):\n",
    "    def __init__(self, activation_branch, activation_trunk, branch_input_dim:int, trunk_input_dim:int, \n",
    "                 branch_hidden_dims:list, trunk_hidden_dims:list, num_basis:int, bc:bool=False):\n",
    "        \"\"\"\n",
    "        DeepONet class. This class defines the architecture of the DeepONet.\n",
    "        The DeepONet is composed of two subnetworks: the branch network and the trunk network.\n",
    "        \n",
    "        Args:\n",
    "        activation: activation function\n",
    "        branch_input_dim: input dimension of the branch network\n",
    "        trunk_input_dim: input dimension of the trunk network\n",
    "        branch_hidden_dims: list of the hidden dimensions of the branch network\n",
    "        trunck_hidden_dims: list of the hidden dimensions of the trunk network\n",
    "        num_basis: number of basis functions\n",
    "        bc: boolean, if True, we multiply the output of the trunk network by x*(1-x) to satisfy the boundary condition\n",
    "        \"\"\"\n",
    "        super(DeepONet, self).__init__()\n",
    "\n",
    "        # The output dimension of the trunk network must be equal to the number of basis functions.\n",
    "        assert trunk_hidden_dims[-1] == num_basis \n",
    "\n",
    "        self.activation_branch = # initialize the branch activation function\n",
    "        self.activation_trunk = # initialize the trunk activation function\n",
    "        self.bc = # store the bc flag\n",
    "        self.branch_net = # create the approximation network\n",
    "        self.trunk_net = # create the decoding network\n",
    "\n",
    "    def forward(self, branch_in, x):\n",
    "        # compute the output of the approximation and decoding NNs\n",
    "\n",
    "        if self.bc:\n",
    "            return #...\n",
    "        else:\n",
    "            return #...\n",
    "\n",
    "    def grad_forward(self, branch_in, x):\n",
    "        # compute the gradient of the ONet at the points x\n",
    "        x.requires_grad_(True)\n",
    "        branch_output = # ...\n",
    "        trunk_output = #...\n",
    "\n",
    "        grad_trunk = torch.zeros_like(trunk_output)\n",
    "\n",
    "        for i in range(trunk_output.shape[1]):\n",
    "            grad_trunk[:, i] = # gradient of trunk_output[:, i] at the points x\n",
    "        if self.bc:\n",
    "            grad_trunk = # update for new formula\n",
    "            return #...\n",
    "        else:\n",
    "            return #...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a DeepONet with proper input dimensions, an activation function (choose one and play with different activation functions), where both trunk and branch nets have a total of `3` layers with hidden dimension `50` and `output_dim = num_basis = 80`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "\n",
    "model = DeepONet(\n",
    "\n",
    "        ).to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vabQWrDFAAJ"
   },
   "source": [
    "# Training\n",
    "We choose the number of epochs and the meta parameters of the training algorithm. We use adam with `MSELoss` to compute the distance between the exact and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "num_epochs = int(5000)\n",
    "learning_rate = 5e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1250, gamma=0.5)\n",
    "\n",
    "# Choose a criterion\n",
    "criterion = nn.MSELoss()\n",
    "# criterion = LprelLoss(2, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We introduce the funciton that performs the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d1ltdIc7Eqde"
   },
   "outputs": [],
   "source": [
    "def train_deeponet(model, x, rhs, solutions, num_epochs, loss_values):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        optimizer.zero_grad() # Zero the gradients\n",
    "        output = model(rhs.to(device), x.to(device)) # Forward pass\n",
    "\n",
    "        loss = criterion(output, solutions.to(device))\n",
    "        loss.backward() # Backward pass\n",
    "        optimizer.step() # Update the weights\n",
    "        loss_values.append(loss.cpu().detach().numpy()) # Store the loss\n",
    "\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4e}')\n",
    "\n",
    "    return loss_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFrTKAYVrsjW"
   },
   "source": [
    "## Training the deepONet\n",
    "\n",
    "The following block of code trains the model for a number of epochs equals to `num_epochs`. Note that if you rerun this block the training of the model **continues** for other `num_epochs` epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(f\"We have already trained the model for {len(loss_values)} epochs.\")\n",
    "except:\n",
    "    loss_values = []\n",
    "    \n",
    "loss_values = train_deeponet(model, x, coefs, solutions, num_epochs, loss_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss function during the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "executionInfo": {
     "elapsed": 770,
     "status": "ok",
     "timestamp": 1722950452008,
     "user": {
      "displayName": "LUCA PELLEGRINI",
      "userId": "06842304188432351891"
     },
     "user_tz": -120
    },
    "id": "zL_mld5R2K-_",
    "outputId": "0793c0ef-868e-4532-8b2d-6593df167d51"
   },
   "outputs": [],
   "source": [
    "plt.semilogy(range(len(loss_values)), loss_values)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Qualitative) evaluation of the trained deepONet\n",
    "\n",
    "The following function computes the predicted values on some coefficients and the corresponding loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_deeponet(model, x, coefs, solutions):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        u_pred = model(coefs.to(device), x.to(device))\n",
    "        loss = criterion(u_pred, solutions.to(device))\n",
    "        print(f'Loss: {loss.item():.4e}')\n",
    "    return u_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then plot the comparison on three random functions from the training set. Launching the code again will show (potentially) new functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1419,
     "status": "ok",
     "timestamp": 1722950453401,
     "user": {
      "displayName": "LUCA PELLEGRINI",
      "userId": "06842304188432351891"
     },
     "user_tz": -120
    },
    "id": "i-yMj1smntCl",
    "outputId": "6eaa2744-c329-46f5-a1fa-cf17e218f353"
   },
   "outputs": [],
   "source": [
    "# Plot results\n",
    "predicted_solutions = evaluate_deeponet(model, x, coefs, solutions)\n",
    "print(solutions.shape)\n",
    "plot_results(x.detach(), solutions, predicted_solutions.detach(), num_samples_to_plot=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now do the same thing with the gradients, still comparing with functions in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_grads = model.grad_forward(coefs, x)\n",
    "plot_results(x.detach(), grad_solutions, predicted_grads.detach(), num_samples_to_plot=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we look at the behaviour on new data, not contained in the training set. We start by loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.load(\"data/x_test.pt\")\n",
    "coefs_test = torch.load(\"data/a_test.pt\")\n",
    "solutions_test = torch.load(\"data/u_test.pt\")\n",
    "grad_solutions_test = torch.load(\"data/gradu_test.pt\")\n",
    "# see the dimension of the data\n",
    "print(\"Dimension of x: \", x_test.shape)\n",
    "print(\"Dimension of coefs: \", coefs_test.shape)\n",
    "print(\"Dimension of solutions: \", solutions_test.shape)\n",
    "print(\"Dimension of solutions: \", grad_solutions_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then compare function values (again, on three randomly chosen functions, this time in the test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predicted_solutions_test = evaluate_deeponet(model, x_test, coefs_test, solutions_test)\n",
    "plot_results(x_test.detach(), solutions_test, predicted_solutions_test.detach(), num_samples_to_plot=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_grads = model.grad_forward(coefs_test, x)\n",
    "plot_results(x.detach(), grad_solutions_test, predicted_grads.detach(), num_samples_to_plot=3)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "MEFA-2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
