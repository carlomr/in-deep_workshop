{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization schemes\n",
    "In this notebook we work on implementing different optimization methods and applying them to the minimization of several bivariate functions. \n",
    "\n",
    "The (python) functions that need to be implemented are the first ones, in order to be able to compute the gradient of a two-dimensional function and to implement the methods of gradient descent with and without momentum, and Nesterov accelerated gradient. In the rest of the notebook, those methods are applied to different functions, from the “simplest” to the most complex. Interactive representations make it possible to visualize the behavior of the algorithms as the step, initial conditions, and number of iterations change.\n",
    "\n",
    "The imports are classical, with the addition of some plotting and error computation functions that are needed to visualize the algorithms (and which are in the file `lab2_auxiliary.py`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact, fixed, IntSlider, FloatSlider\n",
    "import numpy as np\n",
    "\n",
    "from lab2_auxiliary import plot_3D, plot_3D_GD, default_pars, err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the gradient of a two dimensional function\n",
    "In the following function, given a function $f:\\mathbb{R}^2\\to \\mathbb{R}$ and a set of points $(x_i, y_i)_{i=1}^N$, we want to compute\n",
    "$$\n",
    "    (\\nabla f)(x_i , y_i), \\qquad i=1, \\dots, N\n",
    "$$\n",
    "using automatic differentiation. We will use the function `torch.autograd.grad` and a trick, that we will explain in one dimention. Let $g:\\mathbb{R}\\to\\mathbb{R}$. By passing $x_i$ and $g(x_i)$ to `torch.autograd.grad`, we can compute the derivative $g'(x_i) = (\\partial_{x_i} g)(x_i)$; in order to compute the derivative at all $(x_i)_{i=1}^N$, we can exploit the fact that\n",
    "$$\n",
    "\\partial_{x_i}  \\left(\\sum_{i=1}^N g(x_i) \\right)= g'(x_i).\n",
    "$$\n",
    "In other words, if we feed  `torch.autograd.grad` the vector $(x_i)_{i=1}^N $ and the scalar $\\sum_{i=1}^N g(x_i)$, we obtain what we wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(x,y,fun):\n",
    "    x.requires_grad_(True)\n",
    "    y.requires_grad_(True)\n",
    "    u_x = torch.autograd.grad(fun(x,y).sum(),x,create_graph=True)[0]\n",
    "    u_y = torch.autograd.grad(fun(x,y).sum(),y,create_graph=True)[0]\n",
    "    return torch.Tensor([u_x,u_y])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "Complete the following function to implement the gradient descent method: given an initial guess $z_0 = (x_0, y_0)\\in \\mathbb{R}^2$ and a vector $(\\eta_k)_{k=1}^{N_{\\mathrm{epochs}}}$, for $k=1, \\dots, N_{\\mathrm{epochs}}$ compute\n",
    "$$\n",
    "z_k = z_{k-1} - \\eta_k \\nabla f(z_{k-1}).\n",
    "$$\n",
    "If $\\eta_k \\equiv \\eta \\in \\mathbb{R}_+$ for all $k$, the function takes also a scalar $\\eta$ as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GD(x_0,y_0,eta,num_epoch,fun):\n",
    "    X = torch.empty([num_epoch,2])\n",
    "    X[0,:] = torch.Tensor([x_0,y_0]) # a torch.Tensor containing the initial guess\n",
    "\n",
    "    if np.size(eta) == 1: \n",
    "        for i in range(1,num_epoch):\n",
    "            # a for cycle, and the computation of X[k, :] from X[k-1, :]\n",
    "            X[i,:] = X[i-1,:] - eta*grad(X[i-1,0],X[i-1,1],fun)\n",
    "    else:\n",
    "        assert np.size(eta) == num_epoch\n",
    "        for i in range(1,num_epoch):\n",
    "            # similar to above\n",
    "            X[i,:] = X[i-1,:] - eta[i-1]*grad(X[i-1,0],X[i-1,1],fun)\n",
    "\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum\n",
    "We want to implement here a gradient descent method with momentum. Given $x_0$ and $v_0$ in $\\mathbb{R}^2$ and $\\alpha, \\beta\\in \\mathbb{R}_+$, we compute for $k=1, \\dots, N_{\\mathrm{epochs}}$\n",
    "$$\n",
    "      \\begin{aligned}\n",
    "        v_{k} &= \\beta v_{k-1}  -\\alpha \\nabla f(x_{k-1}),\\\\\n",
    "        x_{k} &= x_{k-1} + v_{k}.\n",
    "      \\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum(x_0,y_0,v,beta,eta,num_epochs,fun):\n",
    "    # args: x_0 and y_0 are scalars, v is in R^2 instead\n",
    "    X = torch.empty() # store all values here (we want it for the plots)\n",
    "    V = torch.empty() # here we want to store only v_k and v_{k-1}\n",
    "    X[0,:] = \n",
    "    V[0,:] = \n",
    "    # for cycle here implementing the algorithm\n",
    "    \n",
    "\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nesterov's method\n",
    "We conclude with Nesterov's method. Given $x_0$ and $v_0$ in $\\mathbb{R}^2$ and $\\alpha, \\beta\\in \\mathbb{R}_+$, we compute for $k=1, \\dots, N_{\\mathrm{epochs}}$\n",
    "$$\n",
    "      \\begin{aligned}\n",
    "        v_{k} &= \\beta v_{k-1}  -\\alpha \\nabla f(x_{k-1} + \\beta v_{k-1}),\\\\\n",
    "        x_{k} &= x_{k-1} + v_{k}.\n",
    "      \\end{aligned}\n",
    "$$## Nesterov's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Nesterov(x_0,y_0,v,beta,eta,num_epochs,fun):\n",
    "    X = \n",
    "    V = \n",
    "    \n",
    "    # initialize X_0 V_0\n",
    "\n",
    "    # loop \n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is necessary for the interactive plots in the next sections (and is already complete) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2D_GD_interactive(method, x, y, x_min, y_min, fun, x_0, y_0, eta, num_epochs):\n",
    "    params = default_pars()\n",
    "    params['x_0'] = x_0\n",
    "    params['y_0'] = y_0\n",
    "    params['learning_rate'] = eta\n",
    "    params['num_epochs'] = num_epochs\n",
    "    if method == 'gd':\n",
    "        update = GD(params['x_0'], params['y_0'], params['learning_rate'], params['num_epochs'], fun)\n",
    "    elif method == 'momentum':\n",
    "        update = momentum(params['x_0'], params['y_0'], torch.zeros(2), 0.5, params['learning_rate'], params['num_epochs'], fun)\n",
    "    elif method == 'nesterov':\n",
    "        update = Nesterov(params['x_0'], params['y_0'], torch.zeros(2), 0.5, params['learning_rate'], params['num_epochs'], fun)\n",
    "\n",
    "    x_mesh, y_mesh = torch.meshgrid(x, y, indexing='ij')\n",
    "    with torch.inference_mode():\n",
    "        fig, ax = plt.subplots(figsize = (4,4))\n",
    "        x_plt, y_plt = x_mesh.detach().numpy(), y_mesh.detach().numpy()\n",
    "        contour = ax.contourf(x_plt, y_plt, fun(x_mesh, y_mesh).detach().numpy())\n",
    "\n",
    "        ax.plot(update[:, 0], update[:, 1], marker = 'o', c = 'red', linewidth = 0.7, markersize = 3)\n",
    "        ax.scatter(x_min, y_min, marker = 'X', label = 'global minumum')\n",
    "        ax.set_xlabel('x')\n",
    "        ax.set_ylabel('y')\n",
    "        ax.legend()\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "        fig.colorbar(contour, ax=ax, orientation='vertical', label='Function Value') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A convex (quadratic) function\n",
    "The first example we consider is a simple quadratic function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "    return x**2 + y**2\n",
    "\n",
    "x = torch.linspace(-5, 5, 100).requires_grad_(True)\n",
    "y = torch.linspace(-5, 5, 100).requires_grad_(True)\n",
    "\n",
    "fig = plot_3D(x, y, f)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0, y_0 = 2, 3\n",
    "learning_rate = 0.1\n",
    "num_epochs = 10\n",
    "\n",
    "gd = GD(x_0, y_0, learning_rate, num_epochs, f)\n",
    "\n",
    "fig_3D = plot_3D_GD(x, y, gd[:,0], gd[:,1], f) \n",
    "fig_3D.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = interact(plot_2D_GD_interactive, \n",
    "            method = fixed('gd'),\n",
    "             x = fixed(x), \n",
    "             y = fixed(y), \n",
    "             x_min = fixed(0), \n",
    "             y_min = fixed(0), \n",
    "             fun = fixed(f), \n",
    "             x_0 = FloatSlider(min=-5, max=5, step=0.1, value=2),\n",
    "             y_0 = FloatSlider(min=-5, max=5, step=0.1, value=3),\n",
    "             eta = FloatSlider(min = 0, max = 1, step = 0.01, value=0.1), \n",
    "             num_epochs = IntSlider(min = 1, max = 100, step = 1, value=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = torch.zeros(2)\n",
    "learning_rate = 0.2\n",
    "num_epochs = 10\n",
    "beta = 0.5\n",
    "\n",
    "mom = momentum(x_0, y_0, V, beta, learning_rate, num_epochs, f)\n",
    "\n",
    "fig_3D = plot_3D_GD(x, y, mom[:,0], mom[:,1], f)\n",
    "fig_3D.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "_ = interact(plot_2D_GD_interactive, \n",
    "            method = fixed('momentum'),\n",
    "             x = fixed(x), \n",
    "             y = fixed(y), \n",
    "             x_min = fixed(0), \n",
    "             y_min = fixed(0), \n",
    "             fun = fixed(f), \n",
    "             x_0 = FloatSlider(min=-5, max=5, step=0.1, value=2),\n",
    "             y_0 = FloatSlider(min=-5, max=5, step=0.1, value=3),\n",
    "             eta = FloatSlider(min = 0, max = 1, step = 0.01, value=0.1), \n",
    "             num_epochs = IntSlider(min = 1, max = 100, step = 1, value=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nesterov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.5\n",
    "nes = Nesterov(x_0,y_0,V,beta,learning_rate,num_epochs,f)\n",
    "\n",
    "fig_3D = plot_3D_GD(x, y, nes[:,0], nes[:,1], f)\n",
    "fig_3D.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "_ = interact(plot_2D_GD_interactive, \n",
    "            method = fixed('nesterov'),\n",
    "             x = fixed(x), \n",
    "             y = fixed(y), \n",
    "             x_min = fixed(0), \n",
    "             y_min = fixed(0), \n",
    "             fun = fixed(f), \n",
    "             x_0 = FloatSlider(min=-5, max=5, step=0.1, value=2),\n",
    "             y_0 = FloatSlider(min=-5, max=5, step=0.1, value=3),\n",
    "             eta = FloatSlider(min = 0, max = 1, step = 0.01, value=0.1), \n",
    "             num_epochs = IntSlider(min = 1, max = 100, step = 1, value=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_glob = torch.Tensor([0,0])\n",
    "dist_err_gd = err(gd,min_glob,f)\n",
    "dist_err_mom = err(mom,min_glob,f)\n",
    "dist_err_nes = err(nes,min_glob,f)\n",
    "\n",
    "\n",
    "plt.semilogy(range(len(gd)),dist_err_gd, marker = 'o', label = 'GD')\n",
    "plt.semilogy(range(len(mom)),dist_err_mom,marker = 'x', label = 'Momentum')\n",
    "plt.semilogy(range(len(nes)),dist_err_nes,marker = 'd', label = 'Nesterov')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Distance from the global min')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A function with a local and a global minimum (and saddle points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x,y):\n",
    "    return 2/5 -(1/10)*(5*x**2 + 5*y**2 + 6*x*y - x - 2*y)*torch.exp(-(x**2+y**2))\n",
    "\n",
    "x = torch.linspace(-2,2,100).requires_grad_(True)\n",
    "y = torch.linspace(-2,2,100).requires_grad_(True)\n",
    "\n",
    "plot_3D(x,y,g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0, y_0 = -0, 0\n",
    "learning_rate = 0.1\n",
    "num_epochs = 10\n",
    "\n",
    "gd = GD(x_0,y_0,learning_rate,num_epochs,g)\n",
    "fig_3D = plot_3D_GD(x, y, gd[:,0], gd[:,1], g)\n",
    "fig_3D.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "_ = interact(plot_2D_GD_interactive, \n",
    "            method = fixed('gd'),\n",
    "             x = fixed(x), \n",
    "             y = fixed(y), \n",
    "             x_min = fixed(-0.63), \n",
    "             y_min = fixed(-0.70), \n",
    "             fun = fixed(g), \n",
    "             x_0 = FloatSlider(min=-2, max=2, step=0.1, value=0),\n",
    "             y_0 = FloatSlider(min=-2, max=2, step=0.1, value=0),\n",
    "             eta = FloatSlider(min = 0, max = 1, step = 0.01, value=0.2), \n",
    "             num_epochs = IntSlider(min = 1, max = 100, step = 1, value=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = torch.zeros(2)\n",
    "learning_rate = 0.2\n",
    "num_epochs = 10\n",
    "beta = 0.5\n",
    "\n",
    "mom = momentum(x_0,y_0,V,beta,learning_rate,num_epochs,g)\n",
    "\n",
    "fig_3D = plot_3D_GD(x,y,mom[:,0],mom[:,1],g)\n",
    "fig_3D.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "_ = interact(plot_2D_GD_interactive, \n",
    "            method = fixed('momentum'),\n",
    "             x = fixed(x), \n",
    "             y = fixed(y), \n",
    "             x_min = fixed(-0.63), \n",
    "             y_min = fixed(-0.70), \n",
    "             fun = fixed(g), \n",
    "             x_0 = FloatSlider(min=-2, max=2, step=0.1, value=0),\n",
    "             y_0 = FloatSlider(min=-2, max=2, step=0.1, value=0),\n",
    "             eta = FloatSlider(min = 0, max = 1, step = 0.01, value=0.2), \n",
    "             num_epochs = IntSlider(min = 1, max = 100, step = 1, value=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nesterov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.5\n",
    "nes = Nesterov(x_0,y_0,V,beta,learning_rate,num_epochs,g)\n",
    "\n",
    "fig_3D = plot_3D_GD(x,y,nes[:,0],nes[:,1],g)\n",
    "fig_3D.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "_ = interact(plot_2D_GD_interactive, \n",
    "            method = fixed('nesterov'),\n",
    "             x = fixed(x), \n",
    "             y = fixed(y), \n",
    "             x_min = fixed(-0.63), \n",
    "             y_min = fixed(-0.70), \n",
    "             fun = fixed(g), \n",
    "             x_0 = FloatSlider(min=-2, max=2, step=0.1, value=0),\n",
    "             y_0 = FloatSlider(min=-2, max=2, step=0.1, value=0),\n",
    "             eta = FloatSlider(min = 0, max = 1, step = 0.01, value=0.2), \n",
    "             num_epochs = IntSlider(min = 1, max = 100, step = 1, value=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_glob = torch.Tensor([-0.63,-0.7])\n",
    "dist_err_gd = err(gd,min_glob,g)\n",
    "dist_err_mom = err(mom,min_glob,g)\n",
    "dist_err_nes = err(nes,min_glob,g)\n",
    "\n",
    "plt.semilogy(range(len(gd)),dist_err_gd, marker = 'o', label = 'GD')\n",
    "plt.semilogy(range(len(mom)),dist_err_mom,marker = 'x', label = 'Momentum')\n",
    "plt.semilogy(range(len(nes)),dist_err_nes,marker = 'd', label = 'Nesterov')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Distance from the global min')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An anisotropic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(x,y):\n",
    "    return (1-x)**2+100*(y-x**2)**2\n",
    "\n",
    "x = torch.linspace(-1.5,1.5,100).requires_grad_(True)\n",
    "y = torch.linspace(-1,3,100).requires_grad_(True)\n",
    "\n",
    "plot_3D(x,y,h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0, y_0 = -1, -0.5\n",
    "learning_rate = 0.002\n",
    "num_epochs = 40\n",
    "\n",
    "gd = GD(x_0,y_0,learning_rate,num_epochs,h)\n",
    "fig_3D = plot_3D_GD(x,y,gd[:,0],gd[:,1],h)\n",
    "fig_3D.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "_ = interact(plot_2D_GD_interactive, \n",
    "            method = fixed('gd'),\n",
    "             x = fixed(x), \n",
    "             y = fixed(y), \n",
    "             x_min = fixed(1), \n",
    "             y_min = fixed(1), \n",
    "             fun = fixed(h), \n",
    "             x_0 = FloatSlider(min=-1.5, max=1.5, step=0.1, value=-1),\n",
    "             y_0 = FloatSlider(min=-1, max=3, step=0.1, value=-0.5),\n",
    "             eta = FloatSlider(min = 0, max = 0.004, step = 0.0005, value=0.002, readout_format='.4f'), \n",
    "             num_epochs = IntSlider(min = 1, max = 100, step = 1, value=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = torch.zeros(2)\n",
    "learning_rate = 0.002\n",
    "num_epochs = 10\n",
    "beta = 0.5\n",
    "\n",
    "mom = momentum(x_0,y_0,V,beta,learning_rate,num_epochs,h)\n",
    "\n",
    "fig_3D = plot_3D_GD(x,y,mom[:,0],mom[:,1],h)\n",
    "fig_3D.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "_ = interact(plot_2D_GD_interactive, \n",
    "            method = fixed('momentum'),\n",
    "             x = fixed(x), \n",
    "             y = fixed(y), \n",
    "             x_min = fixed(1), \n",
    "             y_min = fixed(1), \n",
    "             fun = fixed(h), \n",
    "             x_0 = FloatSlider(min=-1.5, max=1.5, step=0.1, value=-1),\n",
    "             y_0 = FloatSlider(min=-1, max=3, step=0.1, value=-0.5),\n",
    "             eta = FloatSlider(min = 0, max = 0.004, step = 0.0005, value=0.002, readout_format='.4f'), \n",
    "             num_epochs = IntSlider(min = 1, max = 100, step = 1, value=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nesterov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.49\n",
    "nes = Nesterov(x_0,y_0,V,beta,learning_rate,num_epochs,h)\n",
    "\n",
    "fig_3D = plot_3D_GD(x,y,nes[:,0],nes[:,1],h)\n",
    "fig_3D.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "_ = interact(plot_2D_GD_interactive, \n",
    "            method = fixed('nesterov'),\n",
    "             x = fixed(x), \n",
    "             y = fixed(y), \n",
    "             x_min = fixed(1), \n",
    "             y_min = fixed(1), \n",
    "             fun = fixed(h), \n",
    "             x_0 = FloatSlider(min=-1.5, max=1.5, step=0.1, value=-1),\n",
    "             y_0 = FloatSlider(min=-1, max=3, step=0.1, value=-0.5),\n",
    "             eta = FloatSlider(min = 0, max = 0.004, step = 0.0005, value=0.002, readout_format='.4f'), \n",
    "             num_epochs = IntSlider(min = 1, max = 100, step = 1, value=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_glob = torch.Tensor([1,1])\n",
    "dist_err_gd = err(gd,min_glob,h)\n",
    "dist_err_mom = err(mom,min_glob,h)\n",
    "dist_err_nes = err(nes,min_glob,h)\n",
    "plt.semilogy(range(len(gd)),dist_err_gd, marker = 'o', label = 'GD')\n",
    "plt.semilogy(range(len(mom)),dist_err_mom,marker = 'x', label = 'Momentum')\n",
    "plt.semilogy(range(len(nes)),dist_err_nes,marker = 'd', label = 'Nesterov')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Distance from the global min')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A function with many local minima/Importance of the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ackley(x,y):\n",
    "    return -20*torch.exp(-0.2*torch.sqrt(0.5*(x**2+y**2)))-torch.exp(0.5*(torch.cos(2*torch.pi*x)+torch.cos(2*torch.pi*y)))+torch.exp(torch.Tensor([1]))+20\n",
    "x = torch.linspace(-4,4,200).requires_grad_(True)\n",
    "y = torch.linspace(-4,4,200).requires_grad_(True)\n",
    "\n",
    "plot_3D(x,y,ackley)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0, y_0 = -2, 3\n",
    "learning_rate = 0.2\n",
    "num_epochs = 10 \n",
    "\n",
    "gd = GD(x_0,y_0,learning_rate,num_epochs,ackley)\n",
    "\n",
    "plot_3D_GD(x,y,gd[:,0],gd[:,1],ackley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "_ = interact(plot_2D_GD_interactive, \n",
    "            method = fixed('gd'),\n",
    "             x = fixed(x), \n",
    "             y = fixed(y), \n",
    "             x_min = fixed(1), \n",
    "             y_min = fixed(1), \n",
    "             fun = fixed(ackley), \n",
    "             x_0 = FloatSlider(min=-4, max=4, step=0.1, value=-2),\n",
    "             y_0 = FloatSlider(min=-4, max=4, step=0.1, value=-3),\n",
    "             eta = FloatSlider(min = 0, max = 1, step = 0.01, value=0.2), \n",
    "             num_epochs = IntSlider(min = 1, max = 100, step = 1, value=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = torch.zeros(2)\n",
    "beta = 0.6\n",
    "mom = momentum(x_0,y_0,V,beta,learning_rate,num_epochs,ackley)\n",
    "plot_3D_GD(x,y,mom[:,0],mom[:,1],ackley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "_ = interact(plot_2D_GD_interactive, \n",
    "            method = fixed('momentum'),\n",
    "             x = fixed(x), \n",
    "             y = fixed(y), \n",
    "             x_min = fixed(1), \n",
    "             y_min = fixed(1), \n",
    "             fun = fixed(ackley), \n",
    "             x_0 = FloatSlider(min=-4, max=4, step=0.1, value=-2),\n",
    "             y_0 = FloatSlider(min=-4, max=4, step=0.1, value=-3),\n",
    "             eta = FloatSlider(min = 0, max = 1, step = 0.01, value=0.2), \n",
    "             num_epochs = IntSlider(min = 1, max = 100, step = 1, value=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nesterov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nes = Nesterov(x_0,y_0,V,beta,learning_rate,num_epochs,ackley)\n",
    "plot_3D_GD(x,y,nes[:,0],nes[:,1],ackley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "_ = interact(plot_2D_GD_interactive, \n",
    "            method = fixed('nesterov'),\n",
    "             x = fixed(x), \n",
    "             y = fixed(y), \n",
    "             x_min = fixed(1), \n",
    "             y_min = fixed(1), \n",
    "             fun = fixed(ackley), \n",
    "             x_0 = FloatSlider(min=-4, max=4, step=0.1, value=-2),\n",
    "             y_0 = FloatSlider(min=-4, max=4, step=0.1, value=-3),\n",
    "             eta = FloatSlider(min = 0, max = 1, step = 0.01, value=0.2), \n",
    "             num_epochs = IntSlider(min = 1, max = 100, step = 1, value=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_glob = torch.Tensor([0,0])\n",
    "dist_err_gd = err(gd,min_glob,ackley)\n",
    "dist_err_mom = err(mom,min_glob,ackley)\n",
    "dist_err_nes = err(nes,min_glob,ackley)\n",
    "\n",
    "N = range(num_epochs)\n",
    "plt.semilogy(N,dist_err_gd, marker = 'o', label = 'GD')\n",
    "plt.semilogy(N,dist_err_mom,marker = 'x', label = 'Momentum')\n",
    "plt.semilogy(N,dist_err_nes,marker = 'd', label = 'Nesterov')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Distance from the global min')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def step_LR(lr_0,num_epochs,step,gamma):\n",
    "    lr = np.zeros(num_epochs)\n",
    "    lr[0] = lr_0\n",
    "    assert step>0\n",
    "    for i in range(1,num_epochs):\n",
    "        if i%step == 0:\n",
    "            lr[i] = gamma*lr[i-1]\n",
    "        else:\n",
    "            lr[i] = lr[i-1]\n",
    "    return lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.2\n",
    "num_epochs = 30\n",
    "\n",
    "gd = GD(x_0,y_0,learning_rate,num_epochs,ackley)\n",
    "\n",
    "plot_3D_GD(x,y,gd[:,0],gd[:,1],ackley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 5\n",
    "gamma = 0.55\n",
    "lr = step_LR(learning_rate,num_epochs,step,gamma)\n",
    "gd_step = GD(x_0,y_0,lr,num_epochs,ackley)\n",
    "\n",
    "plot_3D_GD(x,y,gd_step[:,0],gd_step[:,1],ackley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = range(num_epochs)\n",
    "dist_err_gd = err(gd,min_glob,ackley)\n",
    "dist_err_gd_step = err(gd_step,min_glob,ackley)\n",
    "\n",
    "plt.semilogy(N,dist_err_gd_step, marker = 'o', label = 'Step scheduler')\n",
    "plt.semilogy(N,dist_err_gd, marker = 'x', label = 'Without scheduler')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
