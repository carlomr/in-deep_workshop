{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving an Inverse Problem with Physics-Informed Neural Networks (PINNs)\n",
    "\n",
    "### Problem Statement:\n",
    "We aim to find the scalar parameter $\\alpha \\in \\mathbb{R}$ given a target function $\\tilde{u}$. Specifically, we want to solve the following optimization problem:\n",
    "$$\n",
    "\\text{arg}\\min f(u,\\tilde{u}) = \\| u - \\tilde{u} \\|^2,\n",
    "$$\n",
    "where $u$ satisfies the boundary value problem described by a second-order Partial differential equation (PDE):\n",
    "\\begin{cases}\n",
    "\\displaystyle -\\alpha \\frac{d^2u}{dx^2} = f(x), \\quad x \\in \\Omega = (0,1),\\\\​\n",
    " u(0) = u(1) =  0 . \n",
    "\\end{cases}\n",
    "\n",
    "### Given data:\n",
    "The target function $\\tilde{u}$ is given by:\n",
    "$$\\tilde{u} = \\sin(\\pi x)$$\n",
    "  \n",
    "The function $f(x)$, derived from the assumed true solution, is specified as:\n",
    "$$f = 2 \\pi^2 \\sin(\\pi x).$$\n",
    "\n",
    "-----------------------------\n",
    "\n",
    "# Objective\n",
    "\n",
    "Our goal is to compute the value of $\\alpha$ that best aligns the solution $u(x)$ of the PDE with the given $\\tilde{u}(x)$.\n",
    "To achieve this, we can utilize a Physics-Informed Neural Network (PINN) that integrates the differential equation as a part of its loss function.\n",
    "This approach ensures that the learned solution not fits the data while respecting the underlying \"physics\" described by the PDE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from DNN import DeepNet\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "torch.manual_seed(128)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(x):\n",
    "  return x.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the PINN model\n",
    "we need to define the following components:\n",
    "- The neural network architecture to approximate the solution $u(x)$.\n",
    "- A parameter $\\alpha$ to be optimized to approximate the parameter $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \n",
    "output =\n",
    "hidden_layer =\n",
    "activation_function =\n",
    "\n",
    "FNN = DeepNet()\n",
    "alpha = nn.Parameter().to(device)\n",
    "FNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the points for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = torch.Tensor().to(device)\n",
    "x1 = torch.Tensor().to(device)\n",
    "u_b0 = torch.Tensor().to(device)\n",
    "u_b1 = torch.Tensor().to(device)\n",
    "\n",
    "n_train_points =  # for train\n",
    "n_data_points  = # for data interpolation\n",
    "n_test_points  = # for test\n",
    "\n",
    "x_train = \n",
    "x_data = \n",
    "x_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 1),num =1)  \n",
    "plt.scatter(convert(x_train), np.zeros_like(convert(x_train)), color='red', s=50, marker='x', label='Collocation Points')\n",
    "plt.scatter(convert(x_data), np.zeros_like(convert(x_data)), color='blue', s=50, marker='.', label='Data Points')\n",
    "\n",
    "plt.scatter(convert(x0), np.zeros_like(convert(x0)), color='green', s=50)\n",
    "plt.scatter(convert(x1), np.zeros_like(convert(x1)), color='green', s=50)\n",
    "plt.xlabel('x')\n",
    "plt.yticks([])  \n",
    "plt.title('Collocation Points')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the exact solution and the rhs of the PDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_sol(x):\n",
    "    return \n",
    "\n",
    "alpha_exact = \n",
    "\n",
    "def rhs(x):\n",
    "    return \n",
    "\n",
    "u_exact_train = exact_sol(x_train)\n",
    "rhs_train = rhs(x_train)\n",
    "u_exact_data = exact_sol(x_data)\n",
    "u_exact_test = exact_sol(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loss_ode(Phi,x,rhs,alpha,metric):\n",
    "    x.requires_grad_(True)\n",
    "\n",
    "    u_NN = Phi(x)\n",
    "    u_NN_x = torch.autograd.grad()[0]\n",
    "    u_NN_xx = torch.autograd.grad()[0]\n",
    "\n",
    "    return metric()\n",
    "\n",
    "def eval_loss_pt(Phi,x,y):\n",
    "    return ().pow(2).squeeze()\n",
    "\n",
    "def eval_loss_data(Phi,x,data,metric):\n",
    "    return metric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10000\n",
    "learining_rate = 1e-3\n",
    "alpha = nn.Parameter(torch.Tensor([1]).to(device).requires_grad_(True)) #! what this carefully\n",
    "\n",
    "optimizer = optim.Adam(list(FNN.parameters())+[alpha],lr = 1e-3) #! what this carefully\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer,5000,0.5)\n",
    "\n",
    "loss_values = np.empty([n_epochs+1,5]) #total,ode, b0,b1, data\n",
    "alpha_values = np.empty([n_epochs+1])\n",
    "\n",
    "MSE =  torch.nn.MSELoss()\n",
    "STEP = 100 #save every 100 epochs\n",
    "\n",
    "assert n_epochs%STEP == 0\n",
    "\n",
    "err = np.empty([int(n_epochs/STEP)+1,2])\n",
    "u_animate =  np.empty([int(n_epochs/STEP)+1,n_train_points])\n",
    "err_animate = np.empty([int(n_epochs/STEP)+1,n_train_points])\n",
    "k = 0 \n",
    "\n",
    "for epoch in range(n_epochs+1):\n",
    "\n",
    "    loss_ode = \n",
    "\n",
    "    loss_b0 = \n",
    "    loss_b1 = \n",
    "\n",
    "    loss_data = \n",
    "\n",
    "    loss = \n",
    "\n",
    "    # optimizer zero grad\n",
    "    ...\n",
    "    \n",
    "    # loss backward\n",
    "    ...\n",
    "    \n",
    "    # optimizer step\n",
    "    ...\n",
    "    \n",
    "    # scheduler step\n",
    "    ...\n",
    "\n",
    "\n",
    "    loss_values[epoch,:] = np.stack([convert(loss),convert(loss_ode),convert(loss_b0),convert(loss_b1),convert(loss_data)])\n",
    "    alpha_values[epoch] = alpha\n",
    "    if epoch%STEP == 0:\n",
    "      lr = np.array(scheduler.get_last_lr())\n",
    "    #   u_NN_test =  FNN(x_test)\n",
    "    #   err[k,:] = [L2_diff(convert(FNN(x_train)),u_exact_train), L2_diff(convert(u_NN_test),u_exact_test)]\n",
    "    #   u_animate[k,:]  = convert(FNN(x_sort_train).squeeze())\n",
    "    #   err_animate[k,:]= (np.abs(u_animate[k,:] - u_exact_train_sort.squeeze()))\n",
    "      print(f'Epoch {epoch} || learning rate {lr.squeeze():.2e} ''\\n'\n",
    "            f'Global loss {loss_values[epoch,0]:.2e} || loss ode {loss_values[epoch,1]:.2e} || loss b0 {loss_values[epoch,2]:.2e} || loss b1 {loss_values[epoch,3]:.2e} || loss data {loss_values[epoch,4]:.2e}','\\n')\n",
    "      k+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(n_epochs+1)\n",
    "#y_lims = [np.min(loss_values)*0.8,np.max(loss_values)*1.2]\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize = (15,7), num =4)\n",
    "axs[0].semilogy(epochs,loss_values[:,0])\n",
    "axs[0].set_xlabel('Numeber of Epochs')\n",
    "#axs[0].set_ylim(y_lims)\n",
    "axs[0].grid('on')\n",
    "axs[0].set_title('Global loss')\n",
    "\n",
    "axs[1].semilogy(epochs,loss_values[:,1],label = 'ODE')\n",
    "axs[1].semilogy(epochs,loss_values[:,2],label = 'b0' )\n",
    "axs[1].semilogy(epochs,loss_values[:,3],label = 'b1' )\n",
    "axs[1].semilogy(epochs,loss_values[:,4],label = 'data' )\n",
    "axs[1].set_xlabel('Numeber of Epochs')\n",
    "#axs[1].set_ylim(y_lims)\n",
    "axs[1].legend()\n",
    "axs[1].grid('on')\n",
    "axs[1].set_title('Components loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_NN_test = convert(FNN(x_test))\n",
    "x_test = convert(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2,figsize = (15,7))\n",
    "axs[0].plot(x_test,convert(u_exact_test),label = 'Exact')\n",
    "axs[0].plot(x_test,u_NN_test, label = 'Test prediction')\n",
    "axs[0].set_xlabel('x')\n",
    "axs[0].legend()\n",
    "axs[0].set_title('Comparision')\n",
    "axs[0].grid()\n",
    "\n",
    "axs[1].semilogy(x_test,np.abs(convert(u_exact_test)-u_NN_test))\n",
    "axs[1].set_title('Point-wise error')\n",
    "axs[1].set_xlabel('x')\n",
    "axs[1].set_ylabel('|u - $u_{NN}$|')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs,alpha_values)\n",
    "plt.plot(epochs,alpha_exact*np.ones(alpha_values.shape))\n",
    "plt.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
